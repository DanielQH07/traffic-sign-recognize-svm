{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import pickle\n",
    "from skimage.transform import resize\n",
    "from skimage import feature\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import glob\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' items = os.listdir(folder_path)\\nfolders = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\\nfor folder in folders:\\n    sign_path = os.path.join(folder_path,folder)\\n    sign_items = os.listdir(sign_path)\\n    # Filter out only the files (not directories)\\n    img_dir = [item for item in sign_items if os.path.isfile(os.path.join(sign_path, item))]\\n    if(folder == \"cross_way\" or folder == \"parking\" or folder == \"roundabout\" or folder == \"traight\"):\\n        for img_path in img_dir:\\n            img_p = os.path.join(sign_path,img_path)\\n            img = cv2.imread(img_p)\\n            image_lst.append(img)\\n            label_lst.append(folder) '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\" items = os.listdir(folder_path)\n",
    "folders = [item for item in items if os.path.isdir(os.path.join(folder_path, item))]\n",
    "for folder in folders:\n",
    "    sign_path = os.path.join(folder_path,folder)\n",
    "    sign_items = os.listdir(sign_path)\n",
    "    # Filter out only the files (not directories)\n",
    "    img_dir = [item for item in sign_items if os.path.isfile(os.path.join(sign_path, item))]\n",
    "    if(folder == \"cross_way\" or folder == \"parking\" or folder == \"roundabout\" or folder == \"traight\"):\n",
    "        for img_path in img_dir:\n",
    "            img_p = os.path.join(sign_path,img_path)\n",
    "            img = cv2.imread(img_p)\n",
    "            image_lst.append(img)\n",
    "            label_lst.append(folder) \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"Sign\"\n",
    "def getData(folder):\n",
    "    img_lst = []\n",
    "    lb_lst = []\n",
    "    sign_path = os.path.join(folder_path,folder)\n",
    "    sign_items = os.listdir(sign_path)\n",
    "    # Filter out only the files (not directories)\n",
    "    img_dir = [item for item in sign_items if os.path.isfile(os.path.join(sign_path, item))]\n",
    "    for img_path in img_dir:\n",
    "        img_p = os.path.join(sign_path,img_path)\n",
    "        img = cv2.imread(img_p)\n",
    "        img_lst.append(img)\n",
    "        lb_lst.append(folder)\n",
    "    return img_lst,lb_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forbit,lbfb = getData(\"forbit\")\n",
    "stop,lbs = getData(\"stop\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lst = forbit[24:] + stop\n",
    "label_lst = lbfb[24:] + lbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "print(len(label_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for red\n",
    "def preprocess_img(img):\n",
    "    # Convert to grayscale if the image is in color\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray = img_gray.astype(np.float32)\n",
    "    resized_img = resize(\n",
    "      img_gray,\n",
    "      output_shape=(64,64),\n",
    "      anti_aliasing=True\n",
    "  )\n",
    "    # Extract HOG features\n",
    "    hog_feature = feature.hog(resized_img, orientations=4, pixels_per_cell=(4, 4),\n",
    "                cells_per_block=(2, 2), transform_sqrt = False, block_norm=\"L1\", visualize=False, feature_vector=True)\n",
    "\n",
    "\n",
    "    return hog_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for blue\n",
    "def preprocess_img(img):\n",
    "    # Convert to grayscale if the image is in color\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_gray = img_gray.astype(np.float32)\n",
    "    resized_img = resize(\n",
    "      img_gray,\n",
    "      output_shape=(64,64),\n",
    "      anti_aliasing=True\n",
    "  )\n",
    "    # Extract HOG features\n",
    "    hog_feature = feature.hog(resized_img, orientations=4, pixels_per_cell=(4, 4),\n",
    "                            cells_per_block=(2, 2), transform_sqrt = False, block_norm=\"L1\", visualize=False, feature_vector=True)\n",
    "\n",
    "    return hog_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: \n",
      "(115, 3600)\n"
     ]
    }
   ],
   "source": [
    "img_feature_lst = []\n",
    "for img in image_lst:\n",
    "  hog_feature = preprocess_img(img)\n",
    "  img_feature_lst.append(hog_feature)\n",
    "img_features = np.array(img_feature_lst)\n",
    "print(\"X shape: \")\n",
    "print(img_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(gamma='scale', decision_function_shape= 'ovo',probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(label_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "test_size = 0.2\n",
    "is_shuffle = True\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    img_features,encoded_labels,\n",
    "    test_size = test_size,\n",
    "    random_state = random_state,\n",
    "    shuffle = is_shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurancy:  1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_val)\n",
    "score = accuracy_score(y_pred, y_val)\n",
    "print(\"Accurancy: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"red.pkl\", \"wb\") as f:\n",
    "    pickle.dump(classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for input_img in stop:\n",
    "    normalized_img = preprocess_img(input_img)\n",
    "    y_pred = classifier.predict([normalized_img])[0]\n",
    "    lst.append(y_pred)\n",
    "print(len(lst))\n",
    "print(lst.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"red.pkl\", \"rb\") as f:\n",
    "    red_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal prediction: [1]\n",
      "0.9771326371811536\n",
      "Probability: ['0.0228673628', '0.9771326372']\n",
      "Class with highest: stop\n"
     ]
    }
   ],
   "source": [
    "input_img = cv2.imread(\"image_18.jpg\")\n",
    "normalized_img = preprocess_img(input_img)\n",
    "y_pred = classifier.predict([normalized_img])\n",
    "print(f'Normal prediction: {y_pred}')\n",
    "y_pred_prob = classifier.predict_proba([normalized_img])\n",
    "print(max(y_pred_prob[0]))\n",
    "prediction = np.argmax(y_pred_prob)\n",
    "y_pred_prob = [f'{p:.10f}' for p in y_pred_prob[0]]\n",
    "print(f'Probability: {y_pred_prob}')\n",
    "print(f'Class with highest: {label_encoder.classes_[prediction]}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
